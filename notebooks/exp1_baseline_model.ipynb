{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3924b4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,recall_score, precision_score, f1_score\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a5260c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv').drop(columns=['tweet_id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f025f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c72fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    text = [word.lower() for word in text.split()]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df780e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stopwords_list = set(stopwords.words('english'))\n",
    "    for word in text.split():\n",
    "        if word.lower() in stopwords_list:\n",
    "            text = text.replace(word, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f860d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nums(text):\n",
    "    for char in text:\n",
    "        if char.isdigit():\n",
    "            text = text.replace(char, \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "260f4a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in text.split():\n",
    "        text = text.replace(word, lemmatizer.lemmatize(word))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4f8d75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "502ac2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = remove_punctuation(text)\n",
    "    text = lowercase(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_nums(text)\n",
    "    text = lematize(text)\n",
    "    text = remove_urls(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77048187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(df):\n",
    "    try:\n",
    "        df['content'] = df['content'].astype(str)\n",
    "        df['content'] = df['content'].apply(preprocess_text)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in normalize_text: {e}\")\n",
    "        raise\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c16deda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty          827\n",
       "enthusiasm     759\n",
       "boredom        179\n",
       "anger          110\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46fa6581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73a93fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sentiment'].isin(['happiness', 'sadness'])]\n",
    "df = normalize_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2667c3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>lyin n bed   hedche ughhhhwitin   cll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>sleep  m  thnkng   old frend   wt  s marred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>charvray charlene  love  ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>kelcouch im sorry  least  friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            content\n",
       "1          0              lyin n bed   hedche ughhhhwitin   cll\n",
       "2          0                      funeral ceremonygloomy friday\n",
       "6          0     sleep  m  thnkng   old frend   wt  s marred...\n",
       "8          0                       charvray charlene  love  ms \n",
       "9          0                   kelcouch im sorry  least  friday"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment = df.sentiment.map({\n",
    "    # 'neutral': 0,\n",
    "    # 'worry': 1,\n",
    "    'sadness': 0,\n",
    "    'happiness':1\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a30e4261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10374, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7392e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['content'])\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99a760c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Sudip-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8345</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Sudip-\u001b[1;36m8345\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Sudip-8345/DVC-git-mini-Project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Sudip-8345/DVC-git-mini-Project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Sudip-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8345</span>/DVC-git-mini-Project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Sudip-\u001b[1;36m8345\u001b[0m/DVC-git-mini-Project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/15 01:02:23 INFO mlflow.tracking.fluent: Experiment with name 'tweet_emotion_classification using baseline Logistic Regression ' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/38951ea8ed414071976af1563898ea9c', creation_time=1749929543959, experiment_id='0', last_update_time=1749929543959, lifecycle_stage='active', name='tweet_emotion_classification using baseline Logistic Regression ', tags={}>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='Sudip-8345', repo_name='DVC-git-mini-Project', mlflow=True)\n",
    "mlflow.set_tracking_uri('https://dagshub.com/Sudip-8345/DVC-git-mini-Project.mlflow')\n",
    "\n",
    "mlflow.set_experiment('tweet_emotion_classification using baseline Logistic Regression ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run 14affec8e0414460aad36cdded38d237\n",
      "🏃 View run amusing-squirrel-178 at: https://dagshub.com/Sudip-8345/DVC-git-mini-Project.mlflow/#/experiments/0/runs/14affec8e0414460aad36cdded38d237\n",
      "🧪 View experiment at: https://dagshub.com/Sudip-8345/DVC-git-mini-Project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import joblib\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"Sudip-8345\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"3a7b1bd52c535c004bd9b275516eae784255615d\"\n",
    "mlflow.set_tracking_uri('https://dagshub.com/Sudip-8345/DVC-git-mini-Project.mlflow')\n",
    "\n",
    "# MLflow tracking\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param('vectorizer','bag of words')\n",
    "    mlflow.log_param('model', 'Logistic Regression')\n",
    "    mlflow.log_param('max_features', 1000)\n",
    "    mlflow.log_param('test_size', 0.2)\n",
    "\n",
    "    # Train model\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='binary', zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, average='binary', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='binary', zero_division=0)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "    mlflow.log_metric('recall', recall)\n",
    "    mlflow.log_metric('precision', precision)\n",
    "    mlflow.log_metric('f1_score', f1)\n",
    "\n",
    "    # Save and log model\n",
    "    model_dir = \"exp1_baseline_model\"\n",
    "    import joblib\n",
    "    joblib.dump(model, \"model/logreg_model.pkl\")\n",
    "    mlflow.log_artifact(\"model/logreg_model.pkl\", artifact_path=\"model\")\n",
    "\n",
    "    # Save metrics to file\n",
    "    os.makedirs(\"model\", exist_ok=True)\n",
    "    with open('model/metrics.txt', 'w') as f:\n",
    "        f.write(f'Accuracy: {accuracy}\\n')\n",
    "        f.write(f'Recall: {recall}\\n')\n",
    "        f.write(f'Precision: {precision}\\n')\n",
    "        f.write(f'F1 Score: {f1}\\n')\n",
    "\n",
    "    # Save and log vectorizer (if using CountVectorizer or similar)\n",
    "    # joblib.dump(vectorizer, 'model/bag_of_words_lr.pkl')\n",
    "    if os.path.exists('model/bag_of_words_lr.pkl'):\n",
    "        mlflow.log_artifact('model/bag_of_words_lr.pkl', artifact_path='model')\n",
    "\n",
    "    # Log metrics.txt\n",
    "    mlflow.log_artifact('model/metrics.txt', artifact_path='model')\n",
    "\n",
    "    print(f\"Model saved in run {mlflow.active_run().info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf1fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
